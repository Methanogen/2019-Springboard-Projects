{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/Desktop\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/Desktop\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(r'C:/Users/user/Desktop/Hevrin Data') # r is a raw string, not read as an escape sequence\n",
    "print(os.getcwd())  # so copied and pasted the required files from IDrive located by a search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. DATA WRANGLING TO OBTAIN A TIME SERIES WITH A DATETIME INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2788, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/01/2011</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.600</td>\n",
       "      <td>2.18</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/02/2011</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>2.112</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.07</td>\n",
       "      <td>4.29</td>\n",
       "      <td>8.45</td>\n",
       "      <td>6.08</td>\n",
       "      <td>3.71</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/03/2011</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.69</td>\n",
       "      <td>3.97</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/04/2011</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/05/2011</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.088</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           45    46    47    48    49    50    51    52    53    54  ...   \\\n",
       "0  08/01/2011  0.77  0.64  0.70  0.58  0.58  0.51  0.70  0.70  0.32  ...    \n",
       "1  08/02/2011  0.77  0.64  0.70  0.70  0.58  0.64  0.70  0.38  0.26  ...    \n",
       "2  08/03/2011  1.22  0.70  0.77  0.70  1.09  0.77  0.83  0.38  0.32  ...    \n",
       "3  08/04/2011  0.38  0.58  0.38  0.38  0.38  0.32  0.45  0.38  0.32  ...    \n",
       "4  08/05/2011  0.51  0.70  0.45  0.38  0.51  0.38  0.51  0.32  0.32  ...    \n",
       "\n",
       "      60    61    62    63    64    65    66    67    68    69  \n",
       "0  1.600  2.18  2.50  2.75  3.58  3.33  3.33  3.33  2.62  1.60  \n",
       "1  2.112  1.66  2.43  3.07  4.29  8.45  6.08  3.71  2.75  1.86  \n",
       "2  1.536  2.43  3.20  3.26  2.69  3.97  3.26  3.46  1.47  0.45  \n",
       "3  0.704  2.05  3.39  3.65  3.33  2.56  1.47  1.09  1.22  0.77  \n",
       "4  1.088  1.86  2.75  3.20  2.50  1.92  1.54  1.22  1.22  0.77  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('Hevrin Usage.csv',header= None,skiprows= 17, usecols= [*range(45,70)]) \n",
    "# skip rows st start August 1st\n",
    "# nrows= 730,   nrows st two years to start with: better is all days, then resample to weekly with .resample('W')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns= ['day','00','01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>03/17/2019</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.18</td>\n",
       "      <td>6.78</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/18/2019</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.58</td>\n",
       "      <td>3.97</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.70</td>\n",
       "      <td>...</td>\n",
       "      <td>4.352</td>\n",
       "      <td>6.78</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/19/2019</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              00    01    02    03    04    05    06    07    08    09  ...   \\\n",
       "day                                                                     ...    \n",
       "03/17/2019  0.58  0.45  0.58  0.58  0.45  0.51  0.51  0.51  0.96  2.11  ...    \n",
       "03/18/2019  0.45  0.51  0.51  0.51  0.51  0.51  0.58  3.97  3.33  0.70  ...    \n",
       "03/19/2019  0.58  0.51  0.51   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "\n",
       "               14    15    16    17    18    19    20    21    22    23  \n",
       "day                                                                      \n",
       "03/17/2019  1.024  0.96  0.96  1.22  2.18  6.78  2.75  2.88  0.83  0.51  \n",
       "03/18/2019  4.352  6.78  2.56  0.96  0.45  0.77  0.90  0.83  2.82  0.58  \n",
       "03/19/2019    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df.set_index(df['day'])\n",
    "df= df.drop(['day'], axis=1)\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft= df.stack()\n",
    "dft=dft.reset_index()\n",
    "dft.columns= ['day','hour','kwh'] # where 'day' is string, not DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>kwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/01/2011</td>\n",
       "      <td>00</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/01/2011</td>\n",
       "      <td>01</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/01/2011</td>\n",
       "      <td>02</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/01/2011</td>\n",
       "      <td>03</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/01/2011</td>\n",
       "      <td>04</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>08/01/2011</td>\n",
       "      <td>05</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08/01/2011</td>\n",
       "      <td>06</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08/01/2011</td>\n",
       "      <td>07</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          day hour   kwh\n",
       "0  08/01/2011   00  0.77\n",
       "1  08/01/2011   01  0.64\n",
       "2  08/01/2011   02  0.70\n",
       "3  08/01/2011   03  0.58\n",
       "4  08/01/2011   04  0.58\n",
       "5  08/01/2011   05  0.51\n",
       "6  08/01/2011   06  0.70\n",
       "7  08/01/2011   07  0.70"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 66505 entries, 2011-08-01 00:00:00 to 2019-03-19 02:00:00\n",
      "Data columns (total 5 columns):\n",
      "hour       66505 non-null category\n",
      "kwh        66505 non-null float64\n",
      "weekday    66505 non-null category\n",
      "month      66505 non-null category\n",
      "year       66505 non-null category\n",
      "dtypes: category(4), float64(1)\n",
      "memory usage: 1.3 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>kwh</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-08-01 00:00:00</th>\n",
       "      <td>00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>Monday</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-01 01:00:00</th>\n",
       "      <td>01</td>\n",
       "      <td>0.64</td>\n",
       "      <td>Monday</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-01 02:00:00</th>\n",
       "      <td>02</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Monday</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-01 03:00:00</th>\n",
       "      <td>03</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Monday</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-01 04:00:00</th>\n",
       "      <td>04</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Monday</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    hour   kwh weekday month  year\n",
       "date                                              \n",
       "2011-08-01 00:00:00   00  0.77  Monday     8  2011\n",
       "2011-08-01 01:00:00   01  0.64  Monday     8  2011\n",
       "2011-08-01 02:00:00   02  0.70  Monday     8  2011\n",
       "2011-08-01 03:00:00   03  0.58  Monday     8  2011\n",
       "2011-08-01 04:00:00   04  0.58  Monday     8  2011"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft['date']= pd.to_datetime(dft['day'] + ' ' + dft['hour'] + ':00:00')\n",
    "from datetime import datetime\n",
    "dft['weekday']= dft.date.dt.weekday_name\n",
    "dft['month']= dft.date.dt.month\n",
    "dft['year']= dft.date.dt.year\n",
    "dft.set_index(dft['date'], inplace= True)\n",
    "dft= dft.drop(['day','date'], axis=1)\n",
    "dft['hour']= dft['hour'].astype('category')\n",
    "dft['weekday']= dft['weekday'].astype('category')\n",
    "dft['month']= dft['month'].astype('category')\n",
    "dft['year']= dft['year'].astype('category')\n",
    "dft.info()\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of Seasonal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>kwh</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>01</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>02</td>\n",
       "      <td>0.45</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    hour   kwh weekday month  year\n",
       "date                                              \n",
       "2017-01-01 00:00:00   00  0.51  Sunday     1  2017\n",
       "2017-01-01 01:00:00   01  0.51  Sunday     1  2017\n",
       "2017-01-01 02:00:00   02  0.45  Sunday     1  2017"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_17= dft[dft.year== 2017]\n",
    "df_17.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.51, 0.51, 0.45, 0.51]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwh_17= df_17.kwh.tolist()\n",
    "W_17= kwh_17[0:2184]\n",
    "W_17[0:4]\n",
    "# len(W_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create nested list 13 weeks of 168 hours each for Winter (W)\n",
    "W17_weekly= [ W_17[i:i+168] for i in range(0,2184,168)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for 2016 and add to the W Winter list:\n",
    "df_16= dft[dft.year== 2016]\n",
    "kwh_16= df_16.kwh.tolist()\n",
    "W_16= kwh_16[0:2184]\n",
    "W16_weekly= [W_16[i:i+168] for i in range(0,2184,168)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for 2015 and add to the W Winter list:\n",
    "df_15= dft[dft.year== 2015]\n",
    "kwh_15= df_15.kwh.tolist()\n",
    "W_15= kwh_15[0:2184]\n",
    "W15_weekly= [W_15[i:i+168] for i in range(0,2184,168)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for 2014 and add to the W Winter list:\n",
    "df_14= dft[dft.year== 2014]\n",
    "kwh_14= df_14.kwh.tolist()\n",
    "W_14= kwh_14[0:2184]\n",
    "W14_weekly= [W_14[i:i+168] for i in range(0,2184,168)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W14_weekly[0] \n",
    "len(W14_weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_weekly= W17_weekly + W16_weekly + W15_weekly + W14_weekly  # now have 52 Winter weeks to randomly draw 13 from\n",
    "len(W_weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "mr1= [random.choice(W_weekly) for i in range(13)]  # m1 is Metering Record 1\n",
    "mr1[0]\n",
    "len(mr1) # 13 : so we have a list of lists, drawn at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2184"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now need to flatten the list-of-lists into a single list of length 168 x 14 weeks\n",
    "fmr1 = [item for sublist in mr1 for item in sublist]\n",
    "len(fmr1) # 2184 : a flat list of 13 winter weeks chosen at random \n",
    "# We now need to repeat this 100x and add to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fmr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Winter_list(list):\n",
    "    W= []\n",
    "    for i in range(5):\n",
    "        a= [random.choice(W_weekly) for p in range(13)]     # List Comprehension to draw 13 weeks of 168 hours\n",
    "        b= [item for sublist in a for item in sublist] # Flatten each List-of-lists into a single list\n",
    "        W.append(b)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2184"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c= Winter_list(W_weekly)\n",
    "len(c)      # 5 since range(5)\n",
    "len(c[0])   # 2184, since 168 x 13 weeks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2184, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.DataFrame(fmr1)  # This should work for a list of lists also!!\n",
    "df.shape  # (2184,1)\n",
    "#df.head()  data entered as a single column (but can transpose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.append(df2, ignore_index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2184)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This generates a dataframe from the list of lists; This is exactly what we need!!\n",
    "df2= pd.DataFrame(c)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next add metrics for Classification based on the preceding 2184 hourly observations\n",
    "df2.average= mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['average']= df2.sum(axis = 1, skipna = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2.average[0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "weekly= dft.kwh.resample('W').sum()\n",
    "monthly= 0.25 * dft.kwh.resample('M').sum()\n",
    "plt.plot(weekly)\n",
    "plt.plot(monthly)\n",
    "plt.title('Weekly & Monthly Household Power Consumption in kwh')\n",
    "plt.ylabel('kwh')\n",
    "plt.show()        #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is surprising about the above time series is that despite the family's addition of two energy-intensive children (including due to more laundry and cooking), and a small EV in 2018, replaced by a large EV in 2019, the highest weekly peaks occured not in the last year, but rather in 2012 and 2013. \n",
    "This could be weather related as hot summers and cold winters can materially increase the load.\n",
    "Also the hourly peaks are most relevant, not the weekly totals and this matter needs to be investigated quite separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dft.kwh, bins=30, density= True)\n",
    "plt.title('Histogram of Hourly Power Consumption: August 2012 to Present')\n",
    "plt.xlabel('Hourly Power Consumption in kwh')\n",
    "plt.axvline(dft.kwh.mean(), color='k', linestyle='dashed', linewidth=2)\n",
    "plt.axvline(3.15, color='r', linestyle='dashed', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Python Dictionary of a selection of Load Factors and the respective number of age-equivalent years is provided here:\n",
    "# age_acceleration_factors= {0.64:1, 0.70:2.65, 0.75:5.65, 0.80:11.67, 0.85:23.3, 0.90:38.9, 0.95:70.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# plt.figure() explore with shift-tab-tab with cursor positioned within parentheses\n",
    "plt.figure(figsize= (15,10))    # this now fills the page so detail can be seen!!\n",
    "sns.boxplot(x= dft.hour,y=dft.kwh)\n",
    "plt.axhline(3.15, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.title('Boxplot of Hourly kwh Consumption by the Hour of the Day: August 2012 to Present')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn.boxplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, \n",
    "#                palette=None, saturation=0.75, width=0.8, dodge=True, fliersize=5, linewidth=None, whis=1.5, notch=False, ax=None, **kwargs)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,10)) # Have to record this before the boxplot is called, it seems!\n",
    "sns.boxplot(dft.month, dft.kwh)\n",
    "plt.axhline(3.15, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.title('Boxplot of Hourly Power Consumption by Month')\n",
    "\n",
    "# NB the reason Months 2 & 3 have so many outliers at they include  half a month each of Tesla charging at 10 kwh\n",
    "# Note also the interquartile ranges are exceeded in the months of June, July,and August: so 6 hours/day > 3.15 kwh\n",
    "# March, April, May have the lowest loads die to the mild Spring temperatures (same for October in the Fall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,10)) \n",
    "sns.boxplot(dft.year, dft.kwh)\n",
    "plt.axhline(3.15, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.title('Boxplot of Hourly Power Consumption by Year')\n",
    "# The median consumption in the years 2012 & 2013 is NOT higher than 2014, so perhaps the high weekly \n",
    "# consumption level peaks in those years (see above) was due to weather conditions (eg a hot summer and a high A/C load)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But in fact the years 2018 & 2019 are different\n",
    "In these two years the upper quartile exceeds the 3.15 threshold, so it appears that a quarter of the time the threshold level for accelerating the ageing of the transformer is exceeded. However, this is only on an AVERAGE basis, and so is perhaps unduly conservative as the other [four] households served may have lower power consumption in that hour. Also in 2019 they have not yet acquired EV's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12= dft[dft.year== 2012]\n",
    "df_12.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,10)) \n",
    "# plt.axhline(3.15, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.plot(df_12.kwh)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,10)) \n",
    "plt.axvline(3.15, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.hist(df_12.kwh, bins=20, density= False) # This shows frequencies so we can surmise > 100 hours exceeded threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,10)) \n",
    "plt.axhline(3.15, color='r', linestyle='dashed', linewidth=2)\n",
    "sns.boxplot(x= df_12.hour,y=df_12.kwh)\n",
    "# Importantly this shows that from 1pm through 9pm (so nine hours) the interquartile range exceeds the 3.15 threshold\n",
    "# So if household consumption is correlated (eg due to common very cold and hot temperatures), then premature ageing\n",
    "# is possible (although these loads are linear) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly= df_12.kwh.resample('W').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,10)) \n",
    "plt.title('Histogram of Aggregate Monthly Power Consumption: 2012')\n",
    "plt.ylabel('Power Consumption in kwh')\n",
    "monthly.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Small EV and a Level 1 \"Trickle Charger\" were Acquired in July, 2018¶\n",
    "In the chart below, after July we see relatively little \"white space\" below the red horizontal line, suggesting that the trickle charger was active throughout much of the night.\n",
    "We used to see daly minimums (during the night) of below 1 kwh, but after July the minimums commonly exceeded 1.75 kwh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18= dft[dft.year== 2018]\n",
    "plt.figure(figsize= (15,10)) \n",
    "df_18.kwh.plot()\n",
    "plt.axhline(3.15, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.axhline(5.5, color='g', linestyle='dashed', linewidth=3)\n",
    "\n",
    "plt.title(\"Hourly kwh Consumption in 2018: Level 1 Charger acquired in July\")\n",
    "plt.ylabel(\"kwh\")\n",
    "# plt.axvline(2018-07-01 00:00:00, color='y', linestyle='dashed', linewidth=5)# problem w datetime specification\n",
    "# # plt.axvline(2018-07-01 , color='g', linestyle='dashed', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lows=  (df_18.kwh < 1.75)\n",
    "sum(lows) # Hmmm this is > 75% of the hours so the chart is quite misleading being dominated by the ink for spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18.info() # hour and month are each strings (and categorical variables)\n",
    "df_18.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18['kwhMA8C']= df_18.kwh.rolling(8,center= True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,10))\n",
    "plt.grid(True)\n",
    "# plt.plot(df_18.kwh, label= 'kwh')\n",
    "plt.plot(df_18.kwhMA8C, label= 'Centered 8-hour Moving Average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_18.kwh > 3.15) # so for the whole year 2018, of 8,760 hours just 466 exceeded the hourly threshold of 3.15 kwh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_18.month.isin() # weird 'year' and month behave here like non-strings!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_L1= df_18[df_18.month.isin([1,2,3,4,5,6])]\n",
    "post_L1= df_18[df_18.month.isin([7,8,9,10,11,12])]\n",
    "pre_L1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One possible Signal for Classifying the new use of a Level 1 Charger is the number of times a certain hourly kwh threshold is exceeded\n",
    "For example, in the first half of 2018 not once was an hourly consumption of more than 5.5 kwh recorded.\n",
    "However, after the Level 1 charger was acquired in July, this threshold was exceeded 13 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(pre_L1.kwh > 5.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(post_L1.kwh > 5.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(df_18.kwh > 5.5) # this includes just one month and several days of EV ownership\n",
    "# NEW CODE FOR ROLLING SIGNAL DAILY OR WEEKLY\n",
    "peak_L1= df_18.kwh > 5.5\n",
    "signal_L1= peak_L1.resample('M').sum() # Monthly is a more stable indicator: consistently more than 7x per week!\n",
    "plt.figure(figsize= (15,10))\n",
    "plt.title('Number of Hours per Week that 5.5 kwh L1 Signal Threshold is Exceeded')\n",
    "plt.ylabel('Number of Hours')\n",
    "# plt.axhline(7, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.plot(signal_L1)\n",
    "# Exceeded regularly in Summer only due to AC load!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_7year= dft.kwh > 5.5 # all years, rather than a single year\n",
    "signal_7year= peak_7year.resample('M').sum() # Monthly is a more stable indicator: consistently more than 7x per week!\n",
    "plt.figure(figsize= (15,10))\n",
    "plt.title('Number of Hours per Month that 5.5kwh Signal Threshold is Exceeded')\n",
    "plt.ylabel('Number of Hours')\n",
    "# plt.axhline(7, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.plot(signal_7year)\n",
    "# DWW could refine by specifying hours 6pm to 6am, as years 2102 and 2013 peaks due to an inefficient old AC unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW TROUGH CODE FOR ROLLING SIGNAL DAILY OR WEEKLY: Lows less frequent w Level 1 Charger\n",
    "trough_L1= df_18.kwh < 0.75\n",
    "trough_signal_L1= trough_L1.resample('M').sum() # Weekly is a more stable indicator?\n",
    "plt.figure(figsize= (15,10))\n",
    "plt.title('Number of Hours per Week that 0.75kwh Trough L1 Signal Threshold is Crossed')\n",
    "plt.ylabel('Number of Hours')\n",
    "# plt.axhline(7, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.plot(trough_signal_L1)\n",
    "# DWW NB The low values at Left and right are misleading artefacts of the resample process!!! BEWARE!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another possible Signal for Classifying the new use of a Level 1 Charger is derived from total monthly power consumption\n",
    "\n",
    "The following analysis of (resampled) monthly data explores a potential Level 1 Charger Signal.\n",
    "One idea is that with the acquisition of a Level 1 charger the monthly total kwh consumption should increase.\n",
    "\n",
    "For example, charging for 1,000 miles driven each month would add about 333 kwh per month (since 1 kwh fuels c.3 miles).\n",
    "\n",
    "A monthly_baseline is established, which is the average of the preceding four years (so 2014-2017 here).\n",
    "\n",
    "This is of course just one \"signal\" or feature. It is desireable to posit a number of such features, and then to test which combination of them is most efffective in accurately classifying a large sample of EV's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18.kwh.resample('M').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_17= dft[dft.year== 2017]\n",
    "df_17.kwh.resample('M').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16= dft[dft.year== 2016]\n",
    "df_16.kwh.resample('M').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15= dft[dft.year== 2015]\n",
    "df_15.kwh.resample('M').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15.kwh.resample('M').sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_14= dft[dft.year== 2014]\n",
    "print(df_14.kwh.resample('M').sum().values)\n",
    "df_14.kwh.resample('M').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_baseline= 0.25 * (df_14.kwh.resample('M').sum().values + df_15.kwh.resample('M').sum().values + \n",
    "                   df_16.kwh.resample('M').sum().values + df_17.kwh.resample('M').sum().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(monthly_baseline)\n",
    "plt.plot(df_18.kwh.resample('M').sum().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axhline(0, color='r', linestyle='dashed', linewidth=2) # zero reference\n",
    "plt.axhline(167, color='g', linestyle='dashed', linewidth=3)# 500 miles/month minimum is an extra 167 kwh/month\n",
    "plt.plot(df_18.kwh.resample('M').sum().values - monthly_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeating the above analysis but just for the 12 hours when the EV is likely to be at the residence (hours 0-5, 18-23 ): this yields a sharper contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.head()\n",
    "# dft.hour.isin(['00','01','02','03','04','05','18','19','20','21','22','23']) #12 hours = half day, abbreviation H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_17H= dft[(dft.year== 2017) & (dft.hour.isin(['00','01','02','03','04','05','18','19','20','21','22','23']))]\n",
    "df_17H.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_17H.kwh.resample('M').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18H= dft[(dft.year== 2018) & (dft.hour.isin(['00','01','02','03','04','05','18','19','20','21','22','23']))]\n",
    "df_18H.kwh.resample('M').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18H= dft[(dft.year== 2018) & (dft.hour.isin(['00','01','02','03','04','05','18','19','20','21','22','23']))]\n",
    "df_17H= dft[(dft.year== 2017) & (dft.hour.isin(['00','01','02','03','04','05','18','19','20','21','22','23']))]\n",
    "df_16H= dft[(dft.year== 2016) & (dft.hour.isin(['00','01','02','03','04','05','18','19','20','21','22','23']))]\n",
    "df_15H= dft[(dft.year== 2015) & (dft.hour.isin(['00','01','02','03','04','05','18','19','20','21','22','23']))]\n",
    "df_14H= dft[(dft.year== 2014) & (dft.hour.isin(['00','01','02','03','04','05','18','19','20','21','22','23']))]\n",
    "monthly_baseline_H= 0.25 * (df_14H.kwh.resample('M').sum().values + df_15H.kwh.resample('M').sum().values + \n",
    "                   df_16H.kwh.resample('M').sum().values + df_17H.kwh.resample('M').sum().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(monthly_baseline_H)\n",
    "plt.plot(df_18H.kwh.resample('M').sum().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW CODE TO TRY  FOR MISSING CHART!\n",
    "plt.axhline(0, color='r', linestyle='dashed', linewidth=2) # zero reference\n",
    "plt.axhline(167, color='g', linestyle='dashed', linewidth=3)# 500 miles/month minimum is an extra 167 kwh/month\n",
    "plt.plot(df_18.kwh.resample('M').sum().values - monthly_baseline_H)\n",
    "\n",
    "# Hmmm Chart below does not look correct!! Monthly total increased by 600 kw/month !!  TOO MUCH!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUT THIS VERSION (oddly not executed in the prior Notebook) DOES LOOK OK\n",
    "\n",
    "plt.axhline(0, color='r', linestyle='dashed', linewidth=2)    # zero reference\n",
    "plt.axhline(167, color='g', linestyle='dashed', linewidth=3)  # 500 miles/month minimum is an extra 167 kwh/month\n",
    "plt.axvline(7, color='y', linestyle='dashed', linewidth=5)\n",
    "plt.title('For the year 2018, Monthly Difference between Actual and the 4-Year baseline Consumption in kwh')\n",
    "plt.xlabel('Month of the Year')\n",
    "plt.ylabel('kwh')\n",
    "plt.plot(df_18H.kwh.resample('M').sum().values - monthly_baseline_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Successful Signal for Discerning the Acquisition of a Level 1 EV Charger\n",
    "For the 12 hours (midnight to 6am, 6pm to midnight) that an EV is more likely to be at a residence,a monthly baseline is first established as the average of the preceding (trailing) 4 years, or 48 months.\n",
    "This Baseline is then subtracted from the monthly values of the current year (for just the same 12 hours).\n",
    "If the positive difference exceeds 167 kwh for three consecutive months, then the Residence is classified as owning a Level 1 EV charger. The 167 kwh/month threshold is predicated on an assumed 500 miles driven per month, and that 1 kwh fuels 3 miles of driving.\n",
    "\n",
    "This approach can easily be generalised to the current months versus a four-year moving average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Third possible Signal for Classifying the new use of a Level 1 Charger might derived from sequences of seven hours at night, or minimum threshold levels\n",
    "One characteristic of a Level 1 charger (aka a \"Trickle Charger) is that it is typically charging for a number of consecutive hours. For example, to provide for a 50-mile round trip would require about 17kwh, and at a charging rate of 1.9 kwh, that would take about nine consecutive hours. This might occur from 6pm to 3am, or from 9pm to 6am, for example. An approach that incorporates a seven-hour moving average might provide an indication of whether Level 1 EV charging is occuring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Fourth possible Signal for Classifying the new use of a Level 1 Charger might be derived from a TOU-driven mini-spike\n",
    "Where the EV charger is the customer of an electric utility that offers the option of a so-called \"Time-Of-Use\" (TOU) electricity tariff, EV chargers are incentivized to delay their charging until the onset of a designated \"Off-Peak\" period, which might start as early as 8pm or as late as midnight, and generally extends to 6am: the electricity tariff for the Off-Peak period is usually at a much lower price - even less than half the price for the preceding Peak Period. Most charging devices have timers, and the customers whohave chosen to subscribe to the TOU option therefore often set their timer to the onset of the Off-Peak period. Experience has shown that this tends to create a mini-peak. Incidentally, sometimes this option is offered to all of a utility's customers, while in other cases it may be offered exclusively to EV chargers who have signed up.\n",
    "\n",
    "Since Corn Belt Energy does not currently offer a TOU Plan, this approach is not immediately relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Ensemble Approach to Classification is often Superior\n",
    "\n",
    "Four alternative signals have been outlined above that might be helpful in discerning whether a given household is an EV charger.\n",
    "\n",
    "A statistical analysis can be performed to see which of the four Signals is superior. However,since the approaches are quite different, they may not be fully-correlated with one another. Accordingly, a mixture (ensemble approach) has often been found to be optimal.\n",
    "\n",
    "This can be achieved in many ways, including by assigning appropriate weights to each of the different approaches.\n",
    "\n",
    "Another way is to have a voting procedure. Suppose for example that three of the Signals are used, then each Classifier is assigned one vote, and the maority vote prevails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Management Approach\n",
    "\n",
    "There appears to be a significant assymettry in the cost of different outcomes (in formal terms, in the respective costs of Type I and Type II Classification errors). \n",
    "\n",
    "For example, suppose a household is initially classified by some judicious combination of the above-outlined Signals as having an EV charger, then the next steps may be:\n",
    "\n",
    "(a) investigative (additional information gathering, for example), or \n",
    "\n",
    "(b) Promotional (making a highly attractive offer of some kind, for example to subscribe to a TOU plan, or to so-called Managed Charging).\n",
    "\n",
    "Both of these steps are likely to be relatively inexpensive, and may represent wise precautionary investments with large associated benefits.\n",
    "\n",
    "In contrast, consider the quite different cost of having missed one or more EV chargers served by the same local distribution transformer. Suppose that the transformer is repeatedly loaded during Peak Periods to 90% or more of its capacity, and its life is materially shortened as a result.Eventually a brown-out occurs, with two non-trivial costs. First, the transformer must be replaced, at a cost of the order of $7,500. Second, there may be repuational damage incurred, as all 5-7 households served by that transformer would have suffered from the consequences of the brown-out. Moreover, as such brown-out's become increasingly common in line with projected EV adoption levels, there could be delays in obtaining new transformers, and even in installing them, as qualified work crews become overburdened with such jobs. These costs could easily be one-hundred to one-thousand times higher.\n",
    "\n",
    "Accordingly, it may be prudent to err on the side of caution and notionally classify a household as an EV charger even if the probability assigned by a chosen algorithm is less than 0.5. \n",
    "\n",
    "It would probably be sensible to accord quite different follow-up courses of action depending on whether the assigned probability was 0.3, 0.5, or 0.9. as the saying goes, \"The devil is in the details\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pane\n",
    "df_18H.kwh.resample('M').sum().plot()\n",
    "df_18H.kwh.resample('M').sum().plot()\n",
    "df_18H.kwh.resample('M').sum().plot()\n",
    "df_18H.kwh.resample('M').sum().plot()\n",
    "df_18H.kwh.resample('M').sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Small EV and a Level 1 \"Trickle Charger\" were Acquired in July, 2018\n",
    "After July we see relatively little \"white space\" below the red horizontal line, suggesting that the trickle charger was active throughout much of the night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_19= dft[dft.year== 2019]\n",
    "plt.figure(figsize= (15,10))\n",
    "df_19.kwh.plot()\n",
    "plt.title('Hourly kwh Consumption: Level 2 Charger Acquired February 11th, 2019')\n",
    "plt.ylabel('kwh')\n",
    "plt.axhline(3.15, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.axhline(7, color='g', linestyle='dashed', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Large (Tesla) EV and a Level 2 \"Fast Charger\" were Acquired in February, 2019\n",
    "In mid-February and beyond we see 7 kwh of consumption frequently, while before even with the EV with the smaller battery it had been comparatively rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_19.kwh > 7) # this includes just one month and several days of EV ownership\n",
    "# NEW CODE FOR ROLLING SIGNAL DAILY OR WEEKLY\n",
    "peak= df_19.kwh > 7\n",
    "signal= peak.resample('W').sum() # Weekly is a more stable indicator: consistently more than 7x per week!\n",
    "plt.figure(figsize= (15,10))\n",
    "plt.title('Number of Times per Week that 7 kwh Signal Threshold is Exceeded')\n",
    "plt.ylabel('Number of Times')\n",
    "# plt.axhline(7, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.plot(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_18.kwh > 7)  # for the year, just a single occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_17.kwh > 7)  # for the year,not a single occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_16.kwh > 7)  # for the year, not a single occurrence\n",
    "# Actually a number of occurences in July, 2012 when AC was old and inefficent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establishing a Baseline for Power Consumption using OLS Regression\n",
    "The approach is to use 2017 as a baseline year for purposes of comparison.\n",
    "The year 2018 is unsuitable as the numbers were materially higher in the second half of the year due to the small EV acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: the following analysis takes the one-month, six day period of Tesla ownership and compares it to\n",
    "# a baseline of the the same period for the preceding four years\n",
    "# Can now be updated through mid July from Jeff Hevrin hopefully (uodate from Corn Belt metering data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_19 = dft['2019-02-12':'2019-03-18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_19.kwh) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_19.kwh.resample('D').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_19 = dft['2019-02-12':'2019-03-18'].kwh.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_18 = dft['2018-02-12':'2018-03-18'].kwh.reset_index()\n",
    "k_18[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_17 = dft['2017-02-12':'2017-03-18'].kwh.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_16 = dft['2016-02-12':'2016-03-18'].kwh.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_years= pd.merge(k_16, k_17, left_index= True, right_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_years.head()\n",
    "two_years.columns= ['date_16','kwh_16','date_17','kwh_17']\n",
    "two_years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_years= pd.merge(two_years,k_18, left_index= True, right_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_years.head()\n",
    "three_years.rename(columns= {'kwh_18':'kwh'})\n",
    "three_years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_years= pd.merge(three_years,k_19, left_index= True, right_index= True)\n",
    "four_years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_years.columns= ['date_16','kwh_16','date_17','kwh_17', 'date_18','kwh_18','date_19','kwh_19']\n",
    "four_years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(four_years.kwh_16)\n",
    "plt.plot(four_years.kwh_19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_years['baseline']= (four_years.kwh_16 + four_years.kwh_17 + four_years.kwh_18)/3\n",
    "four_years= four_years.drop(['date_16','date_17','date_18'], axis= 1)\n",
    "four_years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_years['increment']= (four_years.kwh_19 - four_years.baseline)\n",
    "four_years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(four_years.baseline)\n",
    "plt.plot(four_years.increment)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_years['hour']= four_years.date_19.dt.hour\n",
    "four_years['weekday']= four_years.date_19.dt.weekday_name  # weekday to exlore if weekend charging during the day\n",
    "# dft['weekday']= dft.date.dt.weekday_name\n",
    "four_years.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(four_years.increment, bins=24, density= True)\n",
    "plt.title('Histogram of Hourly Difference from Baseline')\n",
    "plt.xlabel('Difference in kwh')\n",
    "# NB Symmetric Distribution centered around zero is likely just random.\n",
    "# We should therefore look at the most common hours for when the difference (aka 'increment') is more than 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_difference= four_years[four_years.increment > 2]\n",
    "big_difference.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(big_difference.increment, bins=24, density= True)\n",
    "plt.title('Histogram of Hourly Difference from Baseline when > 2')\n",
    "plt.xlabel('Difference in kwh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh= big_difference.groupby('hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.mean()\n",
    "print(gh.increment.mean())\n",
    "# VERY INTERESTING THAT NO COUNTS FOR HOURS 2,3,4,5!!! CHARGING PRESUMABLY COMPLETED BY THEN??\n",
    "# possibly bi-modal: hours 0 & 1 are highest, hours 6pm & 10pm are the next most common.\n",
    "# matplotlib.pyplot.bar(x, height, width=0.8, bottom=None, *, align='center', data=None, **kwargs)[source]\n",
    "plt.bar(gh.increment.mean(), height= 10)\n",
    "#plt.plot(gh.increment.mean())\n",
    "# DWW look at .sum() to give total additional \n",
    "# FAILED BAR PLOT ATTEMPT!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw= big_difference.groupby('weekday')\n",
    "print(gw.increment.mean())\n",
    "plt.plot(gw.increment.mean())  # make days properly continuous by making 'weekday' an ordered categorical variable !?\n",
    "# The observed differences could just be random: no evidence of high Weekend charging: Sunday is the lowest day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= four_years.groupby('hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.baseline.mean()\n",
    "plt.plot(g.baseline.mean())\n",
    "plt.plot(g.increment.mean())\n",
    "plt.plot( g.baseline.mean() + g.increment.mean())\n",
    "\n",
    "plt.show()\n",
    "# DWW MUCH BETTER TO DO THIS AS A STACKED BAR CHART????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g.baseline.mean())\n",
    "print(g.increment.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGARITHMIC EXPLORATIONS !!\n",
    "# introduce logarithmic version!\n",
    "import numpy as np \n",
    "df_17= dft[dft.year== 2017]\n",
    "log= np.log(df_17.kwh)     # take log to base Ten (with e we have negative values!!)\n",
    "log[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing by zero error message received.\n",
    "# \"The proper solution here is to add some small epsilon to the argument of log function. What worked for me was\n",
    "\n",
    "# epsilon = 1e-5    \n",
    "\n",
    "# def cost(X, y, theta):\n",
    "    m = X.shape[0]\n",
    "    yp = expit(X @ theta)\n",
    "    cost = - np.average(y * np.log(yp + epsilon) + (1 - y) * np.log(1 - yp + epsilon))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-5  \n",
    "df_17['ln_kwh']= np.log(df_17.kwh + epsilon)\n",
    "df_17.info()\n",
    "df_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL MODEL ONLY: 2017\n",
    "# This version updated by dropping the 'year' variable as redundant (as for 2017 only)\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "m_ln= ols(formula= 'ln_kwh ~ hour + weekday + month', data= df_17).fit()  # .fit() already done (chained)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m_ln.summary())  # Hmmm...R2 has droped from 18% to just 6.5% !!??\n",
    "# this seems to be a much worse model and was examined only because of possible negative values with a non-log model\n",
    "# But to simulate Accelerated Aging we are only interested in the other end of the distribution, \n",
    "# namely the very high values.\n",
    "# CONCLUSION: Better to stay with the non-log formulation for now?(although variance would increase for higher values?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Regression analysis for 2017\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL MODEL ONLY: 2017\n",
    "# This version updated by dropping the 'year' variable as redundant (as for 2017 only)\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "m= ols(formula= 'kwh ~ hour + weekday + month', data= df_17).fit()  # .fit() already done (chained)\n",
    "\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Sample Prediction\n",
    "kwh_pred= m.predict(df_17)\n",
    "kwh_pred[0:24]\n",
    "error= kwh_pred - df_17.kwh\n",
    "error[0:10]\n",
    "sum_of_squares= sum(error**2)\n",
    "sum_of_squares\n",
    "len(kwh_pred)\n",
    "variance= (sum_of_squares/len(kwh_pred))\n",
    "sigma= variance **0.5\n",
    "sigma # for 2017 sigma = 0.72\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN SAMPLE PREDICTION WITH ERROR TERM SIMULATED\n",
    "kwh_pred_w_epsilon= kwh_pred + sigma*np.random.normal(size= len(kwh_pred))\n",
    "kwh_pred_w_epsilon[0:10]\n",
    "# WHOOPS...we have negative hours! eg -1.36 in hour #2: therefore estimate ln kwh ?? (now negatives precluded!!)\n",
    "# Properly should do a test for heteroskedacity??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logarithmic model!?   TEMPORAL MODEL ONLY: 2017\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "m= ols(formula= 'kwh ~ hour + weekday + month', data= df_17).fit()  # .fit() already done (chained)\n",
    "\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "f_date= pd.date_range(start= '1/1/2020', end= '12/31/2020', freq= 'H')  # f prefix for future dates: datetime object\n",
    "dfF= pd.DataFrame(f_date, columns= ['f_date']) # creates df and names the column\n",
    "\n",
    "dfF['hour']= dfF.f_date.dt.hour\n",
    "dfF['weekday']= dfF.f_date.dt.weekday_name\n",
    "dfF['month']= dfF.f_date.dt.month\n",
    "dfF['year']= dfF.f_date.dt.year\n",
    "\n",
    "dfF['hour']= dfF['hour'].astype('category')\n",
    "dfF['weekday']= dfF['weekday'].astype('category')\n",
    "dfF['month']= dfF['month'].astype('category')\n",
    "dfF['year']= dfF['year'].astype('category')\n",
    "dfF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kwh_pred= m.predict(dfF) # data= dfF  need to add an error term, normally distributed\n",
    "# + sig*random.normal(size= len(f_date))  # where sig is standard deviation of error term\n",
    "import numpy as np \n",
    "epsilon= np.random.normal(size= len(f_date)) # need to import !!\n",
    "epsilon[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16= dft[dft.year== 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TEMPORAL MODEL ONLY: 2016\n",
    "# Again, the redundant 'year' variable is dropped.\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "m2= ols(formula= 'kwh ~ hour + weekday + month', data= df_16).fit()  # .fit() already done (chained)\n",
    "\n",
    "print(m2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Temperature variable\n",
    "temps= pd.read_csv('chicago_hourly_temperatures.csv', usecols= [0,17])\n",
    "temps.info()     # Note that the 'datetime variable is in fact just a string, and NOT a datetime object!!!\n",
    "temps.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "temps['date']= pd.to_datetime(temps.datetime)\n",
    "# raw_data['Mycol'] =  pd.to_datetime(raw_data['Mycol'], format='%d%b%Y:%H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.info() # so the conversion was correctly parsed, but the hours appear to be Universal, namely Greenwich (+6)\n",
    "# this is a problem as it does not match the hour in Chicago for the kwh usage !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps['C_date'] = temps.date - dt.timedelta(hours=6) # where 'C_date' is Chicago time.\n",
    "temps.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps['hour']= temps.C_date.dt.hour\n",
    "temps['month']= temps.C_date.dt.month\n",
    "temps['year']= temps.C_date.dt.year\n",
    "temps['F']= 1.8*(temps['Chicago'] - 273.15) + 32\n",
    "temps.set_index(temps['C_date'], inplace= True)\n",
    "temps.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps= temps.drop(['datetime','Chicago','date'], axis=1)\n",
    "temps['F_sqr']= temps.F**2\n",
    "temps['F_cbd']= temps.F**3\n",
    "temps['F_frth']= temps.F**4\n",
    "temps.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_17= temps[temps.year== 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_17.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_17 = pd.merge(df_17, temps_17, left_index= True, right_index= True) # 'left_on= date, right_on= date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_17.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_17.hour_y = comb_17.hour_y.astype('category', ordered= True)\n",
    "comb_17.month_x= comb_17.month_x.astype('category', ordered= True)\n",
    "comb_17.head(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "m_F= ols(formula= 'kwh ~ hour_y + weekday + month_x + F + F_sqr + F_cbd + F_frth', data= comb_17).fit() \n",
    "# .fit() already done (chained)\n",
    "\n",
    "print(m_F.summary())\n",
    "\n",
    "# Hmmm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_17.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat after dropping month variable, seeing if temperature variable F is sufficient on its own\n",
    "m_F_wo_month= ols(formula= 'kwh ~ hour_y + weekday + F + F_sqr + F_cbd + F_frth', data= comb_17).fit() \n",
    "# .fit() already done (chained)\n",
    "\n",
    "print(m_F_wo_month.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= temps.groupby('hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F= 1.8*(g.mean()- 273.15) + 32\n",
    "print(round(F, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('chicago_hourly_temperatures.csv', usecols= [0,17])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb= pd.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS.predict(X)\n",
    "from datetime import datetime\n",
    "dft['weekday']= dft.date.dt.weekday_name\n",
    "dft['month']= dft.date.dt.month\n",
    "dft['year']= dft.date.dt.year\n",
    "dft.set_index(dft['date'], inplace= True)\n",
    "dft= dft.drop(['day','date'], axis=1)\n",
    "dft['hour']= dft['hour'].astype('category')\n",
    "dft['weekday']= dft['weekday'].astype('category')\n",
    "dft['month']= dft['month'].astype('category')\n",
    "dft['year']= dft['year'].astype('category')\n",
    "dft.info()\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "f_date= pd.date_range(start= '1/1/2020', end= '12/31/2020', freq= 'H')  # f prefix for future dates: datetime object\n",
    "dfF= pd.DataFrame(f_dates, columns= ['f_date']) # creates df and names the column\n",
    "dfF['hour']= dfF.dates.dt.month\n",
    "dfF['weekday']= dfF.dates.dt.weekday_name\n",
    "dfF['month']= dfF.dates.dt.month\n",
    "dfF['year']= dfF.dates.dt.year\n",
    "# dft.set_index(dft['date'], inplace= True)\n",
    "# dft= dft.drop(['day','date'], axis=1)\n",
    "dfF['hour']= dfF['hour'].astype('category')\n",
    "dfF['weekday']= dfF['weekday'].astype('category')\n",
    "dfF['month']= dfF['month'].astype('category')\n",
    "dfF['year']= dfF['year'].astype('category')\n",
    "dfF.info()\n",
    "dfF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "dft['weekday']= dft.date.dt.weekday_name\n",
    "dft['month']= dft.date.dt.month\n",
    "dft['year']= dft.date.dt.year\n",
    "dft.set_index(dft['date'], inplace= True)\n",
    "dft= dft.drop(['day','date'], axis=1)\n",
    "dft['hour']= dft['hour'].astype('category')\n",
    "dft['weekday']= dft['weekday'].astype('category')\n",
    "dft['month']= dft['month'].astype('category')\n",
    "dft['year']= dft['year'].astype('category')\n",
    "dft.info()\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "f_date= pd.date_range(start= '1/1/2020', end= '12/31/2020', freq= 'H')  # f prefix for future dates: datetime object\n",
    "dfF= pd.DataFrame(f_date, columns= ['f_date']) # creates df and names the column\n",
    "\n",
    "dfF['hour']= dfF.f_date.dt.hour\n",
    "dfF['weekday']= dfF.f_date.dt.weekday_name\n",
    "dfF['month']= dfF.f_date.dt.month\n",
    "dfF['year']= dfF.f_date.dt.year\n",
    "\n",
    "dfF['hour']= dfF['hour'].astype('category')\n",
    "dfF['weekday']= dfF['weekday'].astype('category')\n",
    "dfF['month']= dfF['month'].astype('category')\n",
    "dfF['year']= dfF['year'].astype('category')\n",
    "dfF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmm for the purely temporal model volatility is underestimated greatly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby hour and month mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "40000000/(42000 * 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # OLD CODE BELOW TO BE EXCISED"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
